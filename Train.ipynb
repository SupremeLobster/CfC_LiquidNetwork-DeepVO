{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c884586c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vilad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data info from datainfo/train_df_t000102050809_v04060710_pNone_seq10x14_sample1.pickle\n",
      "Number of samples in training dataset:  1697\n",
      "Number of samples in validation dataset:  330\n",
      "==================================================\n",
      "CUDA used.\n",
      "Record loss in:  records/t000102050809_v04060710_im92x304_s10x14_b8_lstmTEMP448_optAdamW_base_lr0.002_decay_lr0.97_weight_decay0.0001.txt\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 114\u001b[0m\n\u001b[0;32m    112\u001b[0m t_loss_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    113\u001b[0m train_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dl)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (_, t_x, t_times, t_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_cuda:\n\u001b[0;32m    116\u001b[0m         t_x \u001b[38;5;241m=\u001b[39m t_x\u001b[38;5;241m.\u001b[39mcuda(non_blocking\u001b[38;5;241m=\u001b[39mpar\u001b[38;5;241m.\u001b[39mpin_mem)\n",
      "File \u001b[1;32mc:\\users\\vilad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\vilad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\vilad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:927\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    920\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m--> 927\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\users\\vilad\\appdata\\local\\programs\\python\\python38\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\vilad\\appdata\\local\\programs\\python\\python38\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\vilad\\appdata\\local\\programs\\python\\python38\\lib\\multiprocessing\\context.py:326\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\vilad\\appdata\\local\\programs\\python\\python38\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\users\\vilad\\appdata\\local\\programs\\python\\python38\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from params import par\n",
    "from data_helper import get_data_info, SortedRandomBatchSampler, ImageSequenceDataset, get_partition_data_info\n",
    "from model import DeepVO_CfC\n",
    "import sys\n",
    "import random\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "# Write all hyperparameters to record_path\n",
    "mode = 'a' if par.resume else 'w'\n",
    "with open(par.record_path, mode) as f:\n",
    "    f.write('\\n'+'='*50 + '\\n')\n",
    "    f.write('\\n'.join(\"%s: %s\" % item for item in vars(par).items()))\n",
    "    f.write('\\n'+'='*50 + '\\n')\n",
    "\n",
    "# Prepare Data\n",
    "if os.path.isfile(par.train_data_info_path) and os.path.isfile(par.valid_data_info_path):\n",
    "    print('Load data info from {}'.format(par.train_data_info_path))\n",
    "    train_df = pd.read_pickle(par.train_data_info_path)\n",
    "    valid_df = pd.read_pickle(par.valid_data_info_path)\n",
    "else:\n",
    "    print('Create new data info')\n",
    "    if par.partition != None:\n",
    "        partition = par.partition\n",
    "        train_df, valid_df = get_partition_data_info(partition, par.train_video, par.seq_len, overlap=1, sample_times=par.sample_times, shuffle=True, sort=True)\n",
    "    else:\n",
    "        train_df = get_data_info(folder_list=par.train_video, seq_len_range=par.seq_len, overlap=1, sample_times=par.sample_times)\n",
    "        valid_df = get_data_info(folder_list=par.valid_video, seq_len_range=par.seq_len, overlap=1, sample_times=par.sample_times)\n",
    "    # save the data info\n",
    "    train_df.to_pickle(par.train_data_info_path)\n",
    "    valid_df.to_pickle(par.valid_data_info_path)\n",
    "\n",
    "train_sampler = SortedRandomBatchSampler(train_df, par.batch_size, drop_last=True)\n",
    "train_dataset = ImageSequenceDataset(train_df, par.resize_mode, (par.img_w, par.img_h), par.img_means, par.img_stds, par.minus_point_5)\n",
    "train_dl = DataLoader(train_dataset, batch_sampler=train_sampler, num_workers=par.n_processors, pin_memory=par.pin_mem)\n",
    "\n",
    "valid_sampler = SortedRandomBatchSampler(valid_df, par.batch_size, drop_last=True)\n",
    "valid_dataset = ImageSequenceDataset(valid_df, par.resize_mode, (par.img_w, par.img_h), par.img_means, par.img_stds, par.minus_point_5)\n",
    "valid_dl = DataLoader(valid_dataset, batch_sampler=valid_sampler, num_workers=par.n_processors, pin_memory=par.pin_mem)\n",
    "\n",
    "print('Number of samples in training dataset: ', len(train_df.index))\n",
    "print('Number of samples in validation dataset: ', len(valid_df.index))\n",
    "print('='*50)\n",
    "\n",
    "\n",
    "# Model\n",
    "M_deepvo_cfc = DeepVO_CfC(par.img_h, par.img_w, par.batch_norm)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('CUDA used.')\n",
    "    M_deepvo_cfc = M_deepvo_cfc.cuda()\n",
    "\n",
    "\n",
    "# Load FlowNet weights pretrained with FlyingChairs\n",
    "# NOTE: the pretrained model assumes image rgb values in range [-0.5, 0.5]\n",
    "if par.pretrained_flownet and not par.resume:\n",
    "    if use_cuda:\n",
    "        pretrained_w = torch.load(par.pretrained_flownet)\n",
    "    else:\n",
    "        pretrained_w = torch.load(par.pretrained_flownet_flownet, map_location='cpu')\n",
    "    print('Load FlowNet pretrained model')\n",
    "    # Use only conv-layer-part of FlowNet as CNN for DeepVO_cfc\n",
    "    model_dict = M_deepvo_cfc.state_dict()\n",
    "    update_dict = {k: v for k, v in pretrained_w['state_dict'].items() if k in model_dict}\n",
    "    model_dict.update(update_dict)\n",
    "    M_deepvo_cfc.load_state_dict(model_dict)\n",
    "\n",
    "\n",
    "# Create optimizer\n",
    "if par.optim['opt'] == 'Adam':\n",
    "    optimizer = torch.optim.Adam(M_deepvo_cfc.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "elif par.optim['opt'] == 'Adagrad':\n",
    "    optimizer = torch.optim.Adagrad(M_deepvo_cfc.parameters(), lr=par.optim['lr'])\n",
    "elif par.optim['opt'] == 'Cosine':\n",
    "    optimizer = torch.optim.SGD(M_deepvo_cfc.parameters(), lr=par.optim['lr'])\n",
    "    T_iter = par.optim['T']*len(train_dl)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_iter, eta_min=0, last_epoch=-1)\n",
    "elif par.optim['opt'] == 'AdamW':\n",
    "    optimizer = torch.optim.AdamW(M_deepvo_cfc.parameters(), lr=par.optim['base_lr'], weight_decay=par.optim['weight_decay'])\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=par.optim['decay_lr'])\n",
    "\n",
    "# Load trained DeepVO model and optimizer\n",
    "if par.resume:\n",
    "    M_deepvo_cfc.load_state_dict(torch.load(par.load_model_path))\n",
    "    optimizer.load_state_dict(torch.load(par.load_optimizer_path))\n",
    "    print('Load model from: ', par.load_model_path)\n",
    "    print('Load optimizer from: ', par.load_optimizer_path)\n",
    "\n",
    "\n",
    "# Train\n",
    "print('Record loss in: ', par.record_path)\n",
    "min_loss_t = 1e10\n",
    "min_loss_v = 1e10\n",
    "M_deepvo_cfc.train()\n",
    "for ep in range(par.epochs):\n",
    "    st_t = time.time()\n",
    "    print('='*50)\n",
    "    # Train\n",
    "    M_deepvo_cfc.train()\n",
    "    loss_mean = 0\n",
    "    t_loss_list = []\n",
    "    train_length = len(train_dl)\n",
    "    for i, (_, t_x, t_times, t_y) in enumerate(train_dl):\n",
    "        if use_cuda:\n",
    "            t_x = t_x.cuda(non_blocking=par.pin_mem)\n",
    "            t_y = t_y.cuda(non_blocking=par.pin_mem)\n",
    "            t_times = t_times.cuda(non_blocking=par.pin_mem)\n",
    "        ls = M_deepvo_cfc.step(t_x, t_times, t_y, optimizer).data.cpu().numpy()\n",
    "        t_loss_list.append(float(ls))\n",
    "        loss_mean += float(ls)\n",
    "        print(\" \"*1000, end='\\r')\n",
    "        if par.optim['opt'] == 'Cosine' or par.optim['opt'] == 'AdamW':\n",
    "            print(f'Training epoch {ep+1}: {(100.0*i/train_length):.2f}% - Loss = {float(ls)} - lr = {lr_scheduler.get_last_lr()[0]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Training epoch {ep+1}: {(100.0*i/train_length):.2f}% - Loss = {float(ls)}', end='\\r')\n",
    "    if par.optim['opt'] == 'Cosine' or par.optim['opt'] == 'AdamW':\n",
    "        lr_scheduler.step()\n",
    "    print('\\nTrain take {:.1f} sec'.format(time.time()-st_t))\n",
    "    loss_mean /= len(train_dl)\n",
    "\n",
    "    # Validation\n",
    "    st_t = time.time()\n",
    "    M_deepvo_cfc.eval()\n",
    "    loss_mean_valid = 0\n",
    "    v_loss_list = []\n",
    "    val_length = len(valid_dl)\n",
    "    for i, (_, v_x, v_times, v_y) in enumerate(valid_dl):\n",
    "        print(\" \"*1000, end='\\r')\n",
    "        print(f'Validating epoch {ep+1}: {(100.0*i/val_length):.2f}%', end='\\r')\n",
    "        if use_cuda:\n",
    "            v_x = v_x.cuda(non_blocking=par.pin_mem)\n",
    "            v_y = v_y.cuda(non_blocking=par.pin_mem)\n",
    "            v_times = v_times.cuda(non_blocking=par.pin_mem)\n",
    "            v_ls = M_deepvo_cfc.get_loss(v_x, v_times, v_y).data.cpu().numpy()\n",
    "        v_loss_list.append(float(v_ls))\n",
    "        loss_mean_valid += float(v_ls)\n",
    "    print('\\nValid take {:.1f} sec'.format(time.time()-st_t))\n",
    "    loss_mean_valid /= len(valid_dl)\n",
    "\n",
    "\n",
    "    f = open(par.record_path, 'a')\n",
    "    f.write('Epoch {}\\ntrain loss mean: {}, std: {:.2f}\\nvalid loss mean: {}, std: {:.2f}\\n'.format(ep+1, loss_mean, np.std(t_loss_list), loss_mean_valid, np.std(v_loss_list)))\n",
    "    print('Epoch {}\\ntrain loss mean: {}, std: {:.2f}\\nvalid loss mean: {}, std: {:.2f}\\n'.format(ep+1, loss_mean, np.std(t_loss_list), loss_mean_valid, np.std(v_loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    # save if the training loss decrease\n",
    "    check_interval = 1\n",
    "    if loss_mean < min_loss_t and ep % check_interval == 0:\n",
    "        min_loss_t = loss_mean\n",
    "        print('Save model at ep {}, mean of train loss: {}'.format(ep+1, loss_mean))\n",
    "        torch.save(M_deepvo_cfc.state_dict(), par.save_model_path+'.train')\n",
    "        torch.save(optimizer.state_dict(), par.save_optimzer_path+'.train')\n",
    "    # save if the valid loss decrease\n",
    "    check_interval = 1\n",
    "    if loss_mean_valid < min_loss_v and ep % check_interval == 0:\n",
    "        min_loss_v = loss_mean_valid\n",
    "        print('Save model at ep {}, mean of valid loss: {}'.format(ep+1, loss_mean_valid))  # use 4.6 sec \n",
    "        torch.save(M_deepvo_cfc.state_dict(), par.save_model_path+'.valid')\n",
    "        torch.save(optimizer.state_dict(), par.save_optimzer_path+'.valid')\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a105e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
